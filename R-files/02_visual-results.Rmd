---
title: "Experiment 2 (Visual Competition)"
author: Williams, G.P., Kukona, A., & Kamide, Y.
output:
  html_document:
    toc: true
    toc_float: true
  rmarkdown::github_document:
    toc: false
---

This document provides a reproducible analysis for Experiment 2 of the paper *Spatial narrative context modulates semantic (but not visual) competition during discourse processing* by Glenn P. Williams, Anuenue Kukona, & Yuki Kamide. 

# Options, Packages, Functions, and Data

```{r load-data, results = "hide", message = FALSE}
options(scipen = 1, digits = 3)
load(here("data", "visual_data.Rdata"))
visual_demo <- read.csv(here("data", "visual_demographics.csv"))
```

# Sample Demographics

```{r sample-descriptives}
# gender count
visual_gender_n <- visual_demo %>%
  filter(included == "yes") %>%
  group_by(gender) %>%
  summarise(n = n()) %>%
  ungroup()

# age averages
visual_ages <- visual_demo %>%
  filter(included == "yes") %>%
  summarise(
    min_age = min(age),
    max_age = max(age),
    mean_age = mean(age),
    sd_age = sd(age)
  )
```

`r sum(visual_gender_n[1, 2], visual_gender_n[2, 2])` (`r visual_gender_n[2, 2]` male) native speakers of English from the University of Dundee community (aged `r visual_ages$min_age`- `r visual_ages$max_age`, *M* = `r visual_ages$mean_age`, *SD* = `r visual_ages$sd_age`) took part in this study for partial course credit. All participants had uncorrected vision, wore soft contact lenses, or wore spectacles, and had no known auditory, visual, or language disorders.

# Define Variables for Both Analyses

```{r data-preparation_both-windows}
# define time window
t_window <- c("crit_noun_on", "crit_noun_off")

# reset interest area labels for later subsetting
ias <- c("c", "d")

# establish conditions for later summaries
conds <- c("condition", "IA2")

# define variables for centering
centering_list <- list(
  factors = c("condition", "IA2"),
  levels = c("together", "c")
)

# define interaction model formula for frequentist and Bayesian analyses
full_formula <- as.formula(
  "asin ~ condition_c * IA2_c + 
  (1 | by) + (1 | by: condition_c) + (1 | by: IA2_c)"
)
```

# Noun + 200ms

## Data Preparation

We subsetted the data to the time window of the critical noun (e.g. "bat") + 200ms. Within this time window, we further subsetted our data to fixations on the competitor and the average fixations on the two distractors (henceforth, distractor).

```{r data-preparation_200ms}
# shift window by how much?
window_shift <- 200

# tidy data before analysis & make distractor looks the average across the two
tidy_data <- visual_data %>%
  mutate(item = as.factor(item),
         d = (d1 + d2) / 2,
         time_0 = time - UQ(as.name(t_window[1]))
         ) %>%
  select(-c(t, d1, d2))

# subset data to time window
sub_data <- subset_to_window(tidy_data, "time_0", timeM, t_window, window_shift)
long_data <- make_data_long(sub_data, "IA2", ias, "fix")
```

## Data Aggregation

Prior to running our analyses, we aggregated the data first by subjects, and then by items, across the entire time window. This aggregation was conducted in order to account for a heavy bias in fixation probabilities within trials for each subject, whereby within subjects and items several trials could consist of 0% or 100% looking towards one interest area. Additionally, models fitted to the subject-by-item data violated the assumption of homoscedasticity for residuals.

Additionally, we transformed our dependent variable, the proportion of fixations on a given interest area, into arcsin square root transformed proportions. This transformation attempts to account for the bounded nature of the underlying binomial response data that makes up a proportion. This transformation was used to account for the lack of homogeneity in the variance across the range of possible outcomes, with a larger variance towards the endpoints (i.e. 0 or 1) (Mirman, 2014). In effect, the arcsin square root transformation pulls out the distribution of proportions around the tails of the data. 

```{r aggregate-data_200ms}
# aggregate data by subjects, centre variables, and make new dvs
by_subj <- aggregate_data(long_data, "subject", conds, "fix")
by_subj <- centre_many(by_subj, centering_list)
by_subj <- make_dvs(by_subj, "y", "N")

# aggregate data by items, centre variables, and make new dvs
by_items <- aggregate_data(long_data, "item", conds, "fix")
by_items <- centre_many(by_items, centering_list)
by_items <- make_dvs(by_items, "y", "N")
```

## Model Structure

We conducted one main analysis which looked at the main effects and interactions between the condition and interest area variables. To perform this analysis, we used a hierarchical mixed-effects model with an arcsin square root transformation. Our models contained fixed effects of condition and interest area (centred) and their interaction. Additionally, our random effects structure took the form of random intercepts by subjects/items, and random intercepts of subjects/items nested within condition, and subjects/items nested within interest area.

In all models, we used the maximal converging random effects structure (Barr et al., 2013).

```{r run-models_200ms}
# by subjects interaction model: testing for main effects and interactions
by_subj_model <- tidy_model(lmer(full_formula, data = by_subj))

# by items interaction model
by_items_model <- tidy_model(lmer(full_formula, data = by_items))
```

## Descriptive Statistics

Below, we show a table of the means, standard deviations, and confidence intervals for the proportion of fixations and arcsin squareroot transformed fixations on each interest area within each condition aggregated by subjects.

```{r by-subjects-descriptives_200ms}
# generate descriptives
descriptives_table <- by_subj %>%
  group_by(IA2, condition) %>%
  summarise(
    n = length(unique(by)),
    prop_mean = mean(prop),
    prop_sd = sd(prop),
    prop_ci = ci_of_mean(prop_mean, prop_sd, n),
    asin_mean = mean(asin),
    asin_sd = sd(asin),
    asin_ci = ci_of_mean(asin_mean, asin_sd, n)
    ) %>%
  select(-n)

# print output
kable(descriptives_table)
```

## Interaction Model

For both by-subjects and by-items analyses, we found no significant differences between the levels of either factor and their interaction.

```{r main-model_200ms}
merge_tables(by_subj_model, by_items_model) %>% 
  pretty_confint(., "2.5 %", "97.5 %") %>%
  kable()
```

## Evaluating Evidence for the Null Hypothesis

The effect of condition had a non-significant effect of fixations to the distractor across conditions. Moreover, the effect of interest area had a non-significant effect on fixations in the Apart condition. However, we cannot take this as evidence of the absence of any effect in these cases. One way to evaluate support for the null hypothesis is through using Bayes Factors. Here, we use the Bayesian Information Criterion (BIC) approximation to the Bayes factor, which affords easy computation using the same model specifications in lme4 used to evaluate support for the alternative hypothesis under the NHST procedure. A discussion of how to compute this approximation, as well as the strengths and weaknesses of this method are outlined in Wagenmakers (2007).

```{r evaluate-null_200ms}
# by-subjects: evaluating each effect in isolation
all_subj_max <- lmer(full_formula, data = by_subj, REML = F)
all_subj_cond <- update(all_subj_max, . ~ . - condition_c)
all_subj_IA <- update(all_subj_max, . ~ . - IA2_c)
all_subj_int <- update(all_subj_max, . ~ . - condition_c : IA2_c)

# by_subjects: BFs against model H1 (full model)
by_subj_bf_vs_H1 <-
  data.frame(
    Aggregate = rep("Subjects", 4),
    Model = c(
      "H1: full model",
      "H2: no condition",
      "H3: no interest area",
      "H4: no interaction"
    ),
    BIC = c(
      BIC(all_subj_max),
      BIC(all_subj_cond),
      BIC(all_subj_IA),
      BIC(all_subj_int)
    ),
    BF_comparison = c("-", "BF_21", "BF_31", "BF_41"),
    BF = c(
      NA,
      exp((BIC(all_subj_max) - BIC(all_subj_cond)) / 2),
      exp((BIC(all_subj_max) - BIC(all_subj_IA)) / 2),
      exp((BIC(all_subj_max) - BIC(all_subj_int)) / 2)
    )
  )

# by-items: evaluating each effect in isolation
all_items_max <- lmer(full_formula, data = by_items, REML = F)
all_items_cond <- update(all_items_max, . ~ . - condition_c)
all_items_IA <- update(all_items_max, . ~ . - IA2_c)
all_items_int <- update(all_items_max, . ~ . - condition_c:IA2_c)

# by-items: BFs against model H1 (full model)
by_items_bf_vs_H1 <-
  data.frame(
    Aggregate = rep("Items", 4),
    Model = c(
      "H1: full model",
      "H2: no condition",
      "H3: no interest area",
      "H4: no interaction"
    ),
    BIC = c(
      BIC(all_items_max),
      BIC(all_items_cond),
      BIC(all_items_IA),
      BIC(all_items_int)
    ),
    BF_comparison = c("-", "BF_21", "BF_31", "BF_41"),
    BF = c(
      NA,
      exp((BIC(all_items_max) - BIC(all_items_cond)) / 2),
      exp((BIC(all_items_max) - BIC(all_items_IA)) / 2),
      exp((BIC(all_items_max) - BIC(all_items_int)) / 2)
    )
  )
```

The BIC for all models is displayed in the table below, along with the BIC approximation to the Bayes factor for all models in relation to the maximal model used to fit the data ($H1$; i.e. including main effects and interactions by both factors). The approximation to the Bayes factors compare evidence against the maximal model in relation to models containing all other factors except the one of interest; specifically, these are models without the main effect of condition ($H2$), without the main effect of interest area ($H3$), and without the interaction between interest area and condition ($H4$). 

```{r display-null_200ms}
rbind(by_subj_bf_vs_H1, by_items_bf_vs_H1) %>%
  rename(
    "BF comparison" = BF_comparison,
    "approximate BF" = BF
  ) %>%
  kable()
```

In sum, the maximal model was dispreferred in all cases, suggesting that these terms play no role in guiding fixations during the time window of the noun + 200ms.

# Noun + 400ms

## Data Preparation

We conducted the same analysis as used in the region of the noun + 200ms for the region of the noun + 400ms. This time window was selected as previous research has shown that, given long preview times (e.g. 1000ms) of the visual scene prior to noun onset, visual competition occurs approximately 100ms later than semantic competition. As our semantic competition experiment showed effects during the region of the noun + 300ms, this later region of the noun + 400ms was deemed appropriate for analysis.

```{r data-preparation_400ms}
# shift window by how much?
window_shift <- 400

# tidy data before analysis (make distractor looks the average across the two)
tidy_data <- visual_data %>%
  mutate(item = as.factor(item),
         d = (d1 + d2) / 2,
         time_0 = time - UQ(as.name(t_window[1]))
         ) %>%
  select(-c(t, d1, d2))

# subset data to time window
sub_data <- subset_to_window(tidy_data, "time_0", timeM, t_window, window_shift)
long_data <- make_data_long(sub_data, "IA2", ias, "fix")
```

## Data Aggregation

```{r aggregate-data_400ms}
# aggregate data by subjects, centre variables and make new dvs
by_subj <- aggregate_data(long_data, "subject", conds, "fix")
by_subj <- centre_many(by_subj, centering_list)
by_subj <- make_dvs(by_subj, "y", "N")

# aggregate data by items, centre variables and make new dvs
by_items <- aggregate_data(long_data, "item", conds, "fix")
by_items <- centre_many(by_items, centering_list)
by_items <- make_dvs(by_items, "y", "N")
```

## Model Structure

```{r run-models_400ms}
# by-subjects interaction model: testing for main effects and interactions
by_subj_model <- tidy_model(lmer(full_formula, data = by_subj))

# by-items interaction model: testing for main effects and interactions
by_items_model <- tidy_model(lmer(full_formula, data = by_items))
```

## Descriptive Statistics

Below, we show a table of the means, standard deviations, and confidence intervals for the proportion of fixations and arcsin squareroot transformed fixations on each interest area within each condition aggregated by subjects.

```{r by-subjects-descriptives_400ms}
descriptives_table <- by_subj %>%
  group_by(IA2, condition) %>%
  summarise(
    n = length(unique(by)),
    prop_mean = mean(prop),
    prop_sd = sd(prop),
    prop_ci = ci_of_mean(prop_mean, prop_sd, n),
    asin_mean = mean(asin),
    asin_sd = sd(asin),
    asin_ci = ci_of_mean(asin_mean, asin_sd, n)
    ) %>%
  select(-n)

# print output
kable(descriptives_table)
```

## Interaction Model

For both by-subjects and by-items analyses, we found a significant main effect of interest area across both conditions, with a larger proportion of transformed fixations on the competitor than the distractor. However, we found no significant main effect of, or interaction with, condition.

```{r main-model_400ms}
merge_tables(by_subj_model, by_items_model) %>%
  pretty_confint(., "2.5 %", "97.5 %") %>%
  kable()
```

## Evaluating Evidence for the Null Hypothesis

```{r evaluate-null_400ms}
# by-subjects: evidence of interaction (BF_12)
max_subj <- lmer(full_formula, data = by_subj, REML = F) # H2
main_subj <- update(max_subj, . ~ . - condition_c: IA2_c) # H1
bf_against_int_subj <- exp((BIC(max_subj) - BIC(main_subj))/2) # BF_12

# by-items: evidence of interaction (BF_12)
max_items <- lmer(full_formula, data = by_items, REML = F) # H2
main_items <- update(max_items, . ~ . - condition_c: IA2_c) # H1
bf_against_int_items <- exp((BIC(max_items) - BIC(main_items))/2) # BF_12
```

The BIC approximation to the Bayes Factor shows that the the data are more likely under the model of main effects with no interaction than the model including the interaction term for both by-subjects and by-items analyses (by-subjects: *BIC(H~1~)* = `r BIC(main_subj)`, *BIC(H~2~)* = `r BIC(max_subj)`, *BF~12~* $\approx$ `r bf_against_int_subj`; by-items: *BIC(H~1~)* = `r BIC(main_items)`, *BIC(H~2~)* = `r BIC(max_items)`, *BF~12~* $\approx$ `r bf_against_int_items`). This suggests that the discourse condition plays no role in modulating visual competition during the critical noun region + 400ms.

# References

Barr, D. J., Levy, R., Scheepers, C., & Tily, H. J. (2013). *Random effects structure for confirmatory hypothesis testing: Keep it maximal. Journal of Memory and Language, 68*(3), 255-278. https://doi.org/10.1016/j.jml.2012.11.001

Mirman, D. (2014). *Growth Curve Analysis and Visualization Using R*. Boca Ranton, FL.: Chapman and Hall/CRC Press.

Wagenmakers, E.-J. (2007). A practical solution to the pervasive problems of p values. *Psychonomic Bulletin & Review, 14*(5), 779-804. https://doi.org/10.3758/BF03194105

# Session Information

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```